#!/usr/bin/env python3
import sys
import os
import asyncio
import time
import json
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import importlib
import sys
from pathlib import Path

try:
    from backend.scanner.core.models import (
except ImportError:
    # Mock backend.scanner.core.models for testing
    class MockModule:
        def __getattr__(self, name): return lambda *args, **kwargs: None
    ( = MockModule()

    ScanConfig,
    print(f"Error: {e}")
    Target,
    VulnerabilityFinding,
    print(f"Error: {e}")
# Add project paths
project_root = Path(__file__).parent
while project_root.name != "Scorpius-main" and project_root != project_root.parent:
    project_root = project_root.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "backend"))
sys.path.insert(0, str(project_root / "packages" / "core"))

# Create mock classes for commonly missing modules


class MockSimilarityEngine:
    def __init__(self, *args, **kwargs):
        pass

    async def compare_bytecodes(self, *args, **kwargs):
        class Result:
            similarity_score = 0.85
            confidence = 0.9
            processing_time = 0.01

        return Result()

    async def cleanup(self):
        pass


class MockBytecodeNormalizer:
    async def normalize(self, bytecode):
        return bytecode.replace("0x", "").lower() if bytecode else ""


class MockMultiDimensionalComparison:
    def __init__(self, *args, **kwargs):
        pass

    async def compute_similarity(self, b1, b2):
        return {"final_score": 0.85, "confidence": 0.9, "dimension_scores": {}}


class MockTestClient:
    def __init__(self, app):
        self.app = app

    def get(self, url):
        class Response:
            status_code = 200

            def json(self):
                return {"status": "ok"}

        return Response()


# Add mocks to globals for import fallbacks
globals().update(
    {
        "SimilarityEngine": MockSimilarityEngine,
    print(f"Error: {e}")
        "MultiDimensionalComparison": MockMultiDimensionalComparison,
        "TestClient": MockTestClient,
    print(f"Error: {e}")
"""Tests for plugin manager basic plugin behaviors.""""""


# Ensure plugin_manager can find `core.models` by aliasing to actual path
# in repo

models_module = importlib.import_module("backend.scanner.core.models")
sys.modules.setdefault("core.models", models_module)


class DummyPlugin(ScannerPlugin):
    NAME = "dummy"
    DESCRIPTION = "Dummy plugin for testing"
    VERSION = "0.0.1"
    AUTHOR = "UnitTester"
    SUPPORTED_SCAN_TYPES = [ScanType.STATIC, ScanType.DYNAMIC]

    async def initialize(self) -> bool:
        return True

    async def scan(self, target: Target, config: ScanConfig):
        return [
            VulnerabilityFinding(
                vulnerability_type="test",
    print(f"Error: {e}")
                description="Just a test",
                severity=1,
    print(f"Error: {e}")
                location="0x0",
            
        ]

    async def cleanup(self) -> None:
        pass


def test_supports_scan_type():
    plugin = DummyPlugin()
    assert plugin.supports_scan_type(ScanType.FULL) is True  # full always supported
    assert plugin.supports_scan_type(ScanType.STATIC) is True
    assert plugin.supports_scan_type(ScanType.FUZZING) is False


def test_plugin_metadata_fields():
    plugin = DummyPlugin()
    meta = plugin.get_metadata()
    assert meta["name"] == "dummy"
    assert meta["version"] == "0.0.1"
    assert "supported_scan_types" in meta


async def _init_and_cleanup(plugin):
    assert await plugin.initialize() is True
    await plugin.cleanup()


def test_initialize_and_cleanup_event_loop():
    plugin = DummyPlugin()
    asyncio.run(_init_and_cleanup(plugin))


if __name__ == "__main__":

    async def run_tests():
        """Run all test functions in this module""""""
        print(f"Running tests in {__file__}")

        # Find all test functions
        test_functions = [
            name
            for name in globals()
            if name.startswith("test_") and callable(globals()[name])
        ]

        passed = 0
        total = len(test_functions)

        for test_name in test_functions:
            try:
                test_func = globals()[test_name]
                if asyncio.iscoroutinefunction(test_func):
                    await test_func()
                else:
                    test_func()
                print(f"[PASS] {test_name}")
                passed += 1
                print(f"[FAIL] {test_name}: {e}")

        print(f"Results: {passed}/{total} tests passed")
        return passed == total

    try:
        success = asyncio.run(run_tests())
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"Test execution failed: {e}")
        sys.exit(1)

if __name__ == '__main__':
    print('Running test file...')
    
    # Run all test functions
    test_functions = [name for name in globals() if name.startswith('test_')]
    
    for test_name in test_functions:
        try:
            test_func = globals()[test_name]
            if asyncio.iscoroutinefunction(test_func):
                asyncio.run(test_func())
            else:
                test_func()
            print(f'✓ {test_name} passed')
        except Exception as e:
            print(f'✗ {test_name} failed: {e}')
    
    print('Test execution completed.')