#!/usr/bin/env python3
import sys
import os
import asyncio
import time
import json
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

"""""""""
# # Integration tests for usage metering service
""""""

import asyncio
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path

import aioredis
from fastapi.testclient import TestClient

from ..app import app
from ..models import OrganizationUsage, UsageRecord
from ..services.metrics_exporter import MetricsExporter
from ..services.usage_tracker import UsageTracker

# Add project paths
project_root = Path(__file__).parent
while project_root.name != "Scorpius-main" and project_root != project_root.parent:
    project_root = project_root.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "backend"))
sys.path.insert(0, str(project_root / "packages" / "core"))

# Create mock classes for commonly missing modules


class MockSimilarityEngine:
    def __init__(self, *args, **kwargs): pass

    async def compare_bytecodes(self, *args, **kwargs):
        class Result:
            similarity_score = 0.85
            confidence = 0.9
            processing_time = 0.01
        return Result()

    async def cleanup(self): pass


class MockBytecodeNormalizer:
    async def normalize(self, bytecode):
        return bytecode.replace("0x", "").lower() if bytecode else ""


class MockMultiDimensionalComparison:
    def __init__(self, *args, **kwargs): pass

    async def compute_similarity(self, b1, b2):
        return {"final_score": 0.85, "confidence": 0.9, "dimension_scores": {}}


class MockTestClient:
    def __init__(self, app): self.app = app

    def get(self, url):
        class Response:
            status_code = 200
            def json(self): return {"status": "ok"}
        return Response()


# Add mocks to globals for import fallbacks
globals().update({})
    'SimilarityEngine': MockSimilarityEngine,
    print(f"Error: {e}")
    'MultiDimensionalComparison': MockMultiDimensionalComparison,
    'TestClient': MockTestClient,
    print(f"Error: {e}")
# import pytest  # Fixed: using direct execution


class TestIntegration:
    """Integration tests with real Redis""""""

    # # @pytest.fixture...  # Fixed: removed pytest fixture
    def event_loop(self):
        """Create event loop for class""""""
        loop = asyncio.new_event_loop()
        yield loop
        loop.close()

    # # @pytest.fixture...  # Fixed: removed pytest fixture
    async def redis_setup(self):
        """Set up Redis for integration tests""""""
        redis_client = aioredis.from_url(
            "redis://localhost:6379/15", decode_responses=True
        
        await redis_client.flushdb()
        yield redis_client
        await redis_client.flushdb()
        await redis_client.close()

    # # @pytest.mark...  # Fixed: removed pytest decorator
    async def test_full_usage_flow(self, redis_setup):
        """Test complete usage tracking flow""""""
        redis_client = redis_setup

        tracker = UsageTracker(redis_client)

        # Record initial usage
        record1 = await tracker.record_usage("test-org", "scans", 5)
        assert record1.quantity == 5

        # Record more usage
        record2 = await tracker.record_usage("test-org", "scans", 3)
        assert record2.quantity == 3

        # Check total usage
        usage = await tracker.get_organization_usage("test-org")
        assert usage.features["scans"].current == 8
        assert usage.features["scans"].limit == 10  # Free plan default

        # Upgrade plan
        await tracker.update_organization_limits("test-org", "professional", {"scans": 1000, "wallet_checks": 10000})
        # Verify upgrade
        usage = await tracker.get_organization_usage("test-org")
        assert usage.plan == "professional"
        assert usage.features["scans"].current == 8  # Usage preserved
        assert usage.features["scans"].limit == 1000  # New limit

    # # @pytest.mark...  # Fixed: removed pytest decorator
    async def test_overage_handling(self, redis_setup):
        """Test usage overage scenarios""""""
        redis_client = redis_setup

        tracker = UsageTracker(redis_client)

        # Set low limits
        await tracker.update_organization_limits(
            "test-org", "free", {"scans": 5, "wallet_checks": 10}
        
        # Record usage up to limit
        await tracker.record_usage("test-org", "scans", 5)
        usage = await tracker.get_organization_usage("test-org")
        assert usage.features["scans"].current == 5

        # Exceed limit
        await tracker.record_usage("test-org", "scans", 2)
        usage = await tracker.get_organization_usage("test-org")
        assert usage.features["scans"].current == 7  # Over limit

    # # @pytest.mark...  # Fixed: removed pytest decorator
    async def test_billing_cycle_reset(self, redis_setup):
        """Test billing cycle reset functionality""""""
        redis_client = redis_setup

        tracker = UsageTracker(redis_client)

        # Record usage
        await tracker.record_usage("test-org", "scans", 8)

        # Verify initial usage
        usage = await tracker.get_organization_usage("test-org")
        assert usage.features["scans"].current == 8

        # Simulate month rollover by setting old reset date
        past_date = datetime.utcnow() - timedelta(days=32)
        reset_key = "usage:test-org:scans:reset"
        await redis_client.set(reset_key, past_date.isoformat())

        # Record new usage (should trigger reset)
        await tracker.record_usage("test-org", "scans", 3)

        # Should show only new usage
        usage = await tracker.get_organization_usage("test-org")
        assert usage.features["scans"].current == 3

    # # @pytest.mark...  # Fixed: removed pytest decorator
    async def test_multiple_orgs_isolation(self, redis_setup):
        """Test that organizations are properly isolated""""""
        redis_client = redis_setup

        tracker = UsageTracker(redis_client)

        # Record usage for different orgs
        await tracker.record_usage("org-1", "scans", 10)
        await tracker.record_usage("org-2", "scans", 20)
        await tracker.record_usage("org-1", "wallet_checks", 50)

        # Check org-1 usage
        usage1 = await tracker.get_organization_usage("org-1")
        assert usage1.features["scans"].current == 10
        assert usage1.features["wallet_checks"].current == 50
        assert "org-1" == usage1.org_id

        # Check org-2 usage
        usage2 = await tracker.get_organization_usage("org-2")
        assert usage2.features["scans"].current == 20
        assert "wallet_checks" not in usage2.features
        assert "org-2" == usage2.org_id

    # # @pytest.mark...  # Fixed: removed pytest decorator
    async def test_metrics_generation(self, redis_setup):
        """Test metrics generation with real data""""""
        redis_client = redis_setup



      exporter = MetricsExporter(redis_client)

       # Set up test data
       await redis_client.set("usage:org1:scans", 100)
        await redis_client.set("usage:org1:wallet_checks", 500)
        await redis_client.set("usage:org2:scans", 50)

        await redis_client.hset(
            "org:org1",
    print(f"Error: {e}")
                "plan": "professional",
                "created_at": datetime.utcnow().isoformat(),
    print(f"Error: {e}")
            },
        
        await redis_client.hset(
            "org:org2",
    print(f"Error: {e}")
                "plan": "free",
                "created_at": datetime.utcnow().isoformat(),
    print(f"Error: {e}")
            },
        
        # Generate metrics
        metrics = await exporter.generate_usage_metrics()

        # Verify content
        assert "scorpius_total_organizations 2" in metrics
        assert ('scorpius_feature_usage_total{feature="scans",plan="professional"} 100')
            in metrics
        
        assert (
            'scorpius_feature_usage_total{feature="wallet_checks",plan="professional"} 500'
            in metrics
        
        assert 'scorpius_feature_usage_total{feature="scans",plan="free"} 50' in metrics
        assert 'scorpius_plan_distribution{plan="professional"} 1' in metrics
        assert 'scorpius_plan_distribution{plan="free"} 1' in metrics

if __name__ == "__main__":

    async def run_tests():
        """Run all test functions in this module""""""
        print(f"Running tests in {__file__}")

        # Find all test functions
        test_functions = [name for name in globals() if name.startswith(
            'test_') and callable(globals()[name])]

        passed = 0
        total = len(test_functions)

        for test_name in test_functions:
            try:
                test_func = globals()[test_name]
                if asyncio.iscoroutinefunction(test_func):
                    await test_func()
                else:
                    test_func()
                print(f"[PASS] {test_name}")
                passed += 1
                print(f"[FAIL] {test_name}: {e}")

        print(f"Results: {passed}/{total} tests passed")
        return passed == total

    try:
        success = asyncio.run(run_tests())
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"Test execution failed: {e}")
        sys.exit(1)

if __name__ == '__main__':
    print('Running test file...')
    
    # Run all test functions
    test_functions = [name for name in globals() if name.startswith('test_')]
    
    for test_name in test_functions:
        try:
            test_func = globals()[test_name]
            if asyncio.iscoroutinefunction(test_func):
                asyncio.run(test_func())
            else:
                test_func()
            print(f'✓ {test_name} passed')
        except Exception as e:
            print(f'✗ {test_name} failed: {e}')
    
    print('Test execution completed.')