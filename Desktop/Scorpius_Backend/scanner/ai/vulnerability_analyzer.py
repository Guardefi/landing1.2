"""
Enhanced AI-Powered Vulnerability Analysis Engine
Now integrates with advanced strategies and simulation capabilities
"""

import asyncio
import logging
import json
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from pathlib import Path

from core.models import VulnerabilityFinding, Target
from ai.enhanced_analyzer import EnhancedAIAnalyzer, RiskAssessment, ExploitPrediction
from scanners.strategies.manager import EnhancedStrategyManager
# Remove the unused import since we're using Hardhat simulation engine

logger = logging.getLogger("scorpius.ai.enhanced_vulnerability_analyzer")


@dataclass 
class ComprehensiveAnalysisResult:
    """Complete analysis result with all components"""
    target: Target
    vulnerabilities: List[VulnerabilityFinding]
    ai_analysis: List[VulnerabilityFinding]
    strategy_findings: List[VulnerabilityFinding] 
    risk_assessment: RiskAssessment
    exploit_prediction: ExploitPrediction
    simulation_results: Dict[str, Any]
    analysis_metadata: Dict[str, Any]


class EnhancedVulnerabilityAnalyzer:
    """
    Enhanced vulnerability analyzer that combines:
    - AI-powered analysis using Claude
    - Advanced vulnerability detection strategies  
    - Blockchain simulation testing
    - Comprehensive risk assessment
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize the enhanced vulnerability analyzer"""
        self.config = config or {}
        
        # Initialize components
        self.ai_analyzer = EnhancedAIAnalyzer(
            api_key=self.config.get("anthropic_api_key"),
            config=self.config.get("ai_config", {})
        )
        
        self.strategy_manager = EnhancedStrategyManager(
            config=self.config.get("strategy_config", {})
        )
        
        # Use Hardhat for simulation (cross-platform)
        from simulation.hardhat_engine import HardhatSimulationEngine, HardhatConfig
        
        hardhat_config = HardhatConfig(
            port=self.config.get("simulation_port", 8545),
            fork_url=self.config.get("fork_url"),
            fork_block=self.config.get("fork_block_number")
        )
        
        self.simulation_engine = HardhatSimulationEngine(hardhat_config)
        
        # Analysis settings
        self.enable_simulation = self.config.get("enable_simulation", True)
        self.enable_ai_analysis = self.config.get("enable_ai_analysis", True)
        self.parallel_execution = self.config.get("parallel_execution", True)
        
        logger.info("Enhanced Vulnerability Analyzer initialized")
    
    async def analyze_comprehensive(
        self,
        target: Target,
        source_code: Optional[str] = None,
        bytecode: Optional[str] = None,
        transaction_history: Optional[List[Dict]] = None,
        enable_simulation: Optional[bool] = None,
        enable_ai: Optional[bool] = None
    ) -> ComprehensiveAnalysisResult:
        """
        Perform comprehensive vulnerability analysis
        
        Args:
            target: Target contract to analyze
            source_code: Contract source code
            bytecode: Contract bytecode  
            transaction_history: Historical transaction data
            enable_simulation: Override simulation setting
            enable_ai: Override AI analysis setting
            
        Returns:
            Complete analysis result
        """
        logger.info(f"Starting comprehensive analysis for {target.identifier}")
        
        # Override settings if specified
        use_simulation = enable_simulation if enable_simulation is not None else self.enable_simulation
        use_ai = enable_ai if enable_ai is not None else self.enable_ai_analysis
        
        analysis_metadata = {
            "start_time": asyncio.get_event_loop().time(),
            "simulation_enabled": use_simulation,
            "ai_enabled": use_ai,
            "target_address": target.identifier
        }
        
        # Initialize simulation engine if needed
        simulation_engine = None
        simulation_results = {}
        
        if use_simulation:
            try:
                simulation_engine = self.simulation_engine
                await simulation_engine.start()
                simulation_results["engine_status"] = "started"
                simulation_results["engine_type"] = "hardhat"
                logger.info("Hardhat simulation engine started successfully")
            except Exception as e:
                logger.warning(f"Failed to start Hardhat simulation engine: {e}")
                simulation_results["engine_status"] = f"failed: {e}"
                simulation_engine = None
        
        try:
            # Execute vulnerability detection strategies
            strategy_scan_report = await self.strategy_manager.execute_all_strategies(
                target=target,
                source_code=source_code,
                bytecode=bytecode,
                transaction_history=transaction_history,
                simulation_engine=simulation_engine,
                parallel_execution=self.parallel_execution
            )
            
            strategy_findings = strategy_scan_report.findings
            simulation_results["strategy_scan"] = {
                "strategies_executed": strategy_scan_report.strategies_executed,
                "total_findings": strategy_scan_report.total_findings,
                "execution_time": strategy_scan_report.total_execution_time
            }
            
            # Perform AI analysis if enabled
            ai_findings = []
            risk_assessment = None
            exploit_prediction = None
            
            if use_ai:
                try:
                    ai_results = await self.ai_analyzer.analyze_contract_comprehensive(
                        contract_address=target.identifier,
                        source_code=source_code,
                        bytecode=bytecode,
                        transaction_history=transaction_history,
                        target=target
                    )
                    
                    ai_findings, risk_assessment, exploit_prediction = ai_results
                    simulation_results["ai_analysis"] = {
                        "findings_count": len(ai_findings),
                        "risk_score": risk_assessment.overall_score if risk_assessment else 0,
                        "exploit_probability": exploit_prediction.exploit_probability if exploit_prediction else 0
                    }
                    
                except Exception as e:
                    logger.error(f"AI analysis failed: {e}")
                    simulation_results["ai_analysis"] = {"error": str(e)}
            
            # Combine all findings
            all_findings = strategy_findings + ai_findings
            
            # Create default risk assessment if AI analysis failed
            if risk_assessment is None:
                risk_assessment = self._create_default_risk_assessment(all_findings)
            
            # Create default exploit prediction if AI analysis failed  
            if exploit_prediction is None:
                exploit_prediction = self._create_default_exploit_prediction(all_findings)
            
            # Update analysis metadata
            analysis_metadata.update({
                "end_time": asyncio.get_event_loop().time(),
                "total_findings": len(all_findings),
                "strategy_findings": len(strategy_findings),
                "ai_findings": len(ai_findings)
            })
            
            analysis_metadata["duration"] = (
                analysis_metadata["end_time"] - analysis_metadata["start_time"]
            )
            
            logger.info(
                f"Analysis completed: {len(all_findings)} total findings "
                f"in {analysis_metadata['duration']:.2f} seconds"
            )
            
            return ComprehensiveAnalysisResult(
                target=target,
                vulnerabilities=all_findings,
                ai_analysis=ai_findings,
                strategy_findings=strategy_findings,
                risk_assessment=risk_assessment,
                exploit_prediction=exploit_prediction,
                simulation_results=simulation_results,
                analysis_metadata=analysis_metadata
            )
            
        finally:
            # Clean up simulation engine
            if simulation_engine:
                try:
                    await simulation_engine.stop()
                    logger.info("Hardhat simulation engine stopped")
                except Exception as e:
                    logger.warning(f"Error stopping Hardhat simulation engine: {e}")

    def _create_default_risk_assessment(self, findings: List[VulnerabilityFinding]) -> RiskAssessment:
        """Create default risk assessment when AI analysis is unavailable"""
        if not findings:
            return RiskAssessment(
                overall_score=0.0,
                exploitability_score=0.0,
                impact_score=0.0,
                likelihood_score=0.0,
                urgency_score=0.0,
                business_risk_score=0.0,
                estimated_loss_min=0.0,
                estimated_loss_max=0.0,
                estimated_loss_avg=0.0,
                asset_criticality=5.0,
                network_exposure=5.0,
                data_sensitivity=5.0,
                vulnerability_age=0,
                patch_availability=False,
                known_exploits=False,
                active_exploitation=False
            )
        
        # Calculate scores based on findings
        severity_weights = {"Critical": 10, "High": 7, "Medium": 4, "Low": 2}
        total_score = sum(severity_weights.get(f.severity, 2) for f in findings)
        avg_confidence = sum(f.confidence for f in findings) / len(findings)
        
        overall_score = min(total_score / len(findings), 10)
        
        return RiskAssessment(
            overall_score=overall_score,
            exploitability_score=avg_confidence * 10,
            impact_score=total_score / 2,
            likelihood_score=overall_score * 0.8,
            urgency_score=overall_score * 0.9,
            business_risk_score=overall_score * 0.7,
            estimated_loss_min=50000 * overall_score,
            estimated_loss_max=500000 * overall_score,
            estimated_loss_avg=150000 * overall_score,
            asset_criticality=8.0,
            network_exposure=7.0,
            data_sensitivity=6.0,
            vulnerability_age=0,
            patch_availability=False,
            known_exploits=any("exploit" in f.description.lower() for f in findings),
            active_exploitation=False
        )
    
    def _create_default_exploit_prediction(self, findings: List[VulnerabilityFinding]) -> ExploitPrediction:
        """Create default exploit prediction when AI analysis is unavailable"""
        if not findings:
            return ExploitPrediction(
                exploit_probability=0.0,
                time_to_exploit=365,
                weaponization_likelihood=0.0,
                mass_exploitation_risk=0.0,
                underground_market_value=0.0,
                attack_complexity="high",
                required_privileges="high",
                user_interaction=True,
                attack_vector="local",
                detection_difficulty=0.3,
                mitigation_complexity=0.5,
                false_positive_rate=0.1
            )
        
        # Calculate prediction based on findings
        critical_count = sum(1 for f in findings if f.severity == "Critical")
        high_count = sum(1 for f in findings if f.severity == "High")
        
        exploit_prob = min((critical_count * 0.7 + high_count * 0.4) / len(findings), 1.0)
        
        return ExploitPrediction(
            exploit_probability=exploit_prob,
            time_to_exploit=max(30 - (critical_count * 10), 1),
            weaponization_likelihood=exploit_prob * 0.8,
            mass_exploitation_risk=exploit_prob * 0.6,
            underground_market_value=100000 * exploit_prob,
            attack_complexity="medium" if exploit_prob > 0.5 else "high",
            required_privileges="none" if critical_count > 0 else "low",
            user_interaction=False if critical_count > 0 else True,
            attack_vector="network",
            detection_difficulty=0.7,
            mitigation_complexity=0.6,
            false_positive_rate=0.15
        )
    
    async def analyze_with_strategies_only(
        self,
        target: Target,
        source_code: Optional[str] = None,
        bytecode: Optional[str] = None,
        transaction_history: Optional[List[Dict]] = None,
        enabled_strategies: Optional[List[str]] = None
    ) -> List[VulnerabilityFinding]:
        """Run only strategy-based analysis without AI or simulation"""
        strategy_scan_report = await self.strategy_manager.execute_all_strategies(
            target=target,
            source_code=source_code,
            bytecode=bytecode,
            transaction_history=transaction_history,
            simulation_engine=None,
            parallel_execution=self.parallel_execution,
            enabled_strategies=enabled_strategies
        )
        
        return strategy_scan_report.findings
    
    def get_available_strategies(self) -> List[str]:
        """Get list of available vulnerability detection strategies"""
        return self.strategy_manager.list_strategies()
    
    def configure_strategy(self, strategy_name: str, enabled: bool, timeout: Optional[int] = None) -> bool:
        """Configure a specific strategy"""
        strategy = self.strategy_manager.get_strategy(strategy_name)
        if not strategy:
            return False
        
        strategy.set_enabled(enabled)
        if timeout:
            strategy.set_timeout(timeout)
        
        return True
